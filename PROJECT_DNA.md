ğŸš€ **SYSTEM PRESERVATION PROMPT (FOR AGENT)** ğŸš€
You are working on the "AI LMS System". Before writing ANY code, you must acknowledge the following CORE SYSTEMS. Do not break them while fixing new bugs:

# 1. ğŸ§  PEDAGOGICAL CORE (The Wizdi-Bot Standard)
## 1.0 CORE DIRECTIVES ("The Halls of Justice")
1. **Strict Grounding (Anti-Hallucination):**
   - Base all content ONLY on the provided `sourceText`.
   - **Manual Override:** When generating single questions via UI (Open/MC/Cloze, etc.), the full `course.fullBookContent` MUST be passed to the context. Title-only generation is FORBIDDEN.
   - **CRITICAL:** Do NOT invent metaphors, analogies, or "fluff" not present in the source.
2. **The "Interactive-Chunk" Rule (NO WALL OF TEXT):**
   - **CRITICAL:** Every single text chunk MUST be immediately followed by a question.
   - **PROHIBITED:** Do not output two text chunks in a row without a question in between.
   - **The Gap-Fill Rule:** If you have more chunks than requested interaction types, you MUST generate **Multiple Choice** questions for the intermediate chunks to ensure interaction at every step.
3. **The "Distinct-Chunk" Rule (Segmentation):**
   - Scan for ALL distinct logical segments (Case Studies, Periods).
   - **Constraint:** Do NOT merge multiple distinct topics into one step (e.g., "China" and "Alaska" must be separate).
4. **Logic Safety:**
   - **Categorization:** Categories must be **MUTUALLY EXCLUSIVE** (e.g., "Causes" vs "Results"). Never use overlapping categories like "Danger" vs "High Risk".
   - **Ordering:** Must be based on objective criteria found in the text (Time, Complexity).
5. **The "Zero-Text-Wall" Rule (V4 Anti-Batching):**
   - **CRITICAL:** The AI Generation Loop must inject a question after *every* single text chunk.
   - **Prohibition:** It is forbidden to output Text Chunk A -> Text Chunk B -> Question.
   - **Mandate:** The structure must be Text Chunk A -> Question A -> Text Chunk B -> Question B.
   - **Fallback:** If the user did not request enough question types, the AI must auto-generate "Multiple Choice" questions for the intermediate chunks.

## 1.1 The Bloom's Taxonomy Matrix (Strict Mapping)
| Bloom Level | Cognitive Goal | Allowed Interaction Types | Feedback Strategy |
| :--- | :--- | :--- | :--- |
| **Foundation** <br>*(Remember/Understand)* | Establish facts, definitions, and basic concepts. | â€¢ **Multiple Choice** (Single Correct)<br>â€¢ **True/False**<br>â€¢ **Matching** (Term <-> Definition) | **Direct correction.** <br>Explain clearly WHY the answer is correct/incorrect immediately. |
| **Connection** <br>*(Apply/Analyze)* | Understand relationships, processes, and categories. | â€¢ **Ordering** (Chronological/Logical)<br>â€¢ **Chat/Grouping** (Categorization)<br>â€¢ **Scenario MC** (Application) | **Progressive Hints.**<br>Do not give the answer immediately. Guide the user: "Look at paragraph 2...", "Think about the order of operations..." |
| **Synthesis** <br>*(Evaluate/Create)* | Critical thinking, judgment, and creation. | â€¢ **Open Question** (Reflection)<br>â€¢ **Complex Scenario MC** (Judgment)<br>â€¢ **Debate** (Bot Interaction) | **Reflective/Model Answer.**<br>For open questions, provide a "Model Answer" for comparison. Encourage deeper thought ("What if X changed?"). |

## 1.2 Feedback Architecture (Detailed)
- **Immediate Feedback:** Must be provided for *every* closed interaction (MC, Ordering, Matching).
- **Reference Back:** Feedback must explicitly cite the `sourceText` if available (e.g., "As described in the 'History' section...").
- **Bot Persona Nuance:**
    - *Socratic:* Answers a question with a guiding question.
    - *Coach:* Challenges correct answers to ensure deep understanding.
    - *Teacher:* Encourages and simplifies.

## 1.3 Complexity Adaptation (Age Appropriateness)
- **Logic:** The `gradeLevel` parameter is a HARD CONSTRAINT, not a suggestion.
- **Rule:** If the `sourceText` is academic/complex but `gradeLevel` is young (Elementary/Middle School):
    - **MUST:** Rewrite content in simple language.
    - **MUST:** Break long paragraphs into short chunks.
    - **MUST:** Explicitly explain difficult terms.
    - **FORBIDDEN:** Copy-pasting complex blocks without adaptation.
- **Prompt Requirement:** Always include: "ADAPT COMPLEXITY TO TARGET AUDIENCE: ${gradeLevel}".

## 1.4 Pedagogical Scaffolding (Hints & Feedback)
- **Logic:** Testing is learning. Guide the student to the answer WITHOUT giving it away.
- **Rule 1 (Progressive Hints):** EVERY interaction must include 2-3 levels of hints using the **Scaffolding** method:
    1. **Level 1 (Location Pointer):** Point to the specific text segment. "Look closely at the sentence starting with..." (Hebrew: "×©×™× ×œ×‘ ×œ××©×¤×˜ ×©××ª×—×™×œ ×‘...").
    2. **Level 2 (Concept Simplification):** Rephrase the relevant sentence in simpler words. "The text explains X... which option matches?"
    3. **Level 3 (Almost Answer):** Strong nudge if needed.
- **Rule 2 (Feedback Architecture):**
    - **Incorrect:** Explain WHY the specific choice is wrong ("Option B talks about X, but we need Y").
    - **Correct:** Affirmative + brief reinforcement.
- **Rule 2 (Feedback Architecture):**
    - **Incorrect:** Explain WHY it's wrong + **MANDATORY Source Reference** ("As written in line 5...").
    - **Correct:** Affirmative + brief reinforcement.
- **Rule 3 (UI/UX Behavior):**
    - **Hint Timing:** Hints are **HIDDEN** by default. They appear only AFTER a mistake or manual request, to encourage independent thinking.
    - **Open Question Loop:** Must support **"Draft -> Feedback -> Retry"**. The system guides, it doesn't just judge. Allow students to fix their answer.
# 2. ğŸ’¾ DATA INTEGRITY (The Memory)
## 2.1 Content Integrity (No Empty Blocks)
- **Logic:** The AI is creative but inconsistent. The Code must be Robust.
- **Rule:** Frontend components (Ordering, Categorization) MUST NEVER receive empty items.
- **Implementation:** The Mapping Layer (`mapSystemItemToBlock`) must normalize diverse AI outputs (strings, objects, `text` vs `content` props) into a STRICT schema before data reaches the UI.

## 2.2 Ingestion Wizard Data
- **Logic:** The `course.wizardData` object is the Source of Truth.
- **Rule:** NEVER delete or flatten this object. Always map `wizardData.settings` (like `botPersona`, `activityLength`) to the generation functions.

# 3. ğŸ›¡ï¸ SECURITY & AUTH (The Shield)
- **Logic:** All DB writes must pass Firestore Rules (`auth != null`).
- **Rule:** Never bypass `useAuth`. Never expose API Keys (use `openaiProxy`).

# 4. ğŸ¨ UI/UX DNA (The Skin)
- **Logic:** Glassmorphism (`bg-white/90`, `backdrop-blur`) + RTL Alignment.
- **Logic:** Glassmorphism (`bg-white/90`, `backdrop-blur`) + RTL Alignment.
- **Rule 1:** No empty loading states (use Skeletons). Ensure Wizard remains responsive (max-w logic).
- **Rule 2 (Data Safety):** The Editor must implement "Unsaved Changes Protection" (`isDirty` state). A user attempting to leave with unsaved changes must be warned via a distinct alert.
- **Rule 3 (AI Assist):** Every content block type (**Categorization, Ordering, Fill-in-Blanks, Memory Game**) must offer a "Create with AI" button (`handleAutoGenerate...`) to reduce teacher friction.

# 5. ğŸ§© MODULE INTEGRITY & SYSTEM MAP
## 5.1 Core Modules (The Nervous System)
- **Gemini Service (`src/gemini.ts`):** The Brain & Hands AI Engine. Manages the generation lifecycle, prompt engineering, and parsing logic (`mapSystemItemToBlock`).
- **Unit Editor (`src/components/UnitEditor.tsx`):** The Teacher's Workshop. Handles manual editing, "Unsaved Changes" protection (`isDirty`), and Media Integration (Upload/AI/Link).
- **Course Player:** The Student Experience. Renders the interactive blocks and manages the "Wizdi Pyramid" flow.
- **Citation Service (`src/services/citationService.ts`):** The Grounding Engine. Splits text into paragraphs and enforces the [Inline Citation] protocol.

## 5.2 Routing Rules
- **Rule:** Don't break the [App.tsx](cci:7://file:///c:/Users/eyal.BONUS/Desktop/ai-lms-system/src/App.tsx:0:0-0:0) routing. [handleWizardComplete](cci:1://file:///c:/Users/eyal.BONUS/Desktop/ai-lms-system/src/App.tsx:134:2-267:4) must handle the delicate handoff from Wizard -> Editor without flashing the Dashboard.

# 6. ğŸ“œ INLINE CITATIONS & GROUNDING V2
## 6.1 The "NotebookLM" Standard
- **Goal:** Every claim must be verifiable.
- **Mechanism:** `CitationService.chunkText` splits source material into numbered paragraphs ([1], [2], [3]).
- **Rule:** The AI must append `[X]` to every factual statement.
- **UI:** The Course Player must render these citations as clickable links that scroll the Source Text into view (Split View).

## 6.2 Grounding Prompt Protocol
- **Constraint:** System Prompts must include:
  1. **Numbered Context:** The source text pre-processed with IDs.
  2. **Strict Citation Rule:** "Every single claim... MUST be followed by a citation."
  3. **No Outside Knowledge:** "If it's not in the text, it doesn't exist."

**INSTRUCTION:** If a user request contradicts these rules, STOP and warn the user. Prioritize system integrity over quick fixes.

# 7. ğŸ§  ADVANCED PEDAGOGICAL INTEGRITY (Refinements)
## 6.1 Micro-Learning Progression (The "Anti-Amnesia" Rule)
- **Problem:** Parallel generation causes each step to repeat definitions (Redundancy).
- **Rule:** Each step must assume the previous steps have been read.
- **Implementation:** "Treat this step as Chapter X of a continuous story. Do NOT define terms defined in Chapters 1-(X-1). Focus ONLY on the new sub-topic in the context of the whole."

## 6.2 Implicit Ordering (The "Anti-Spoiler" Rule)
- **Problem:** Numerical lists in text make "Order the steps" questions trivial visual matching tasks.
- **Rule:** IF interaction is `ordering`:
    - **Text:** MUST be written as a narrative flow (paragraphs only). NO numbered lists.
    - **Question:** Items must be paraphrased (synonyms/rephrasing) to force reading comprehension.

## 6.3 Concrete Analogies (Age Adaptation)
- **Target:** Grades 1-6.
- **Rule:** Every abstract/technical term (e.g., "Chlorophyll", "Molecule") MUST be immediately followed by a concrete analogy from daily life (e.g., "like a solar panel on a roof").

## 6.4 Dynamic Feedback Guidelines
- **Open Questions:** Do not provide a static "Correct Answer". Instead, provide "Evaluator Guidelines" for the Tutor AI (e.g., "Check if the student mentioned both X and Y").

# 8. ğŸ—ï¸ AI ARCHITECTURE (Brain & Hands)
## 7.1 The Core Concept
- **Logic:** To achieve "Parallel Speed" with "Linear Coherence", we split generation into two distinct roles.
## 6.5 Tone & Register (Grade 7+)
- **Rule:** For Grade 7 and above, avoid "Second-Person" narrative (e.g., "Imagine yourself...").
- **Requirement:** Use an **Objective, Historical Tone**. Treat the student as a researcher/scholar, not a child.

## 6.6 Categorization Logic
- **Rule:** Categories must be **Functional** or **Binary** (e.g., "Cause vs Effect", "Problem vs Solution", "Physical vs Digital").
- **Prohibition:** Do NOT use abstract or overlapping categories (e.g., "Feelings" vs "Experiences"). Categories must be mutually exclusive.

# 8. ğŸ—ï¸ AI ARCHITECTURE (Brain & Hands)
## 7.1 The Core Concept
- **Logic:** To achieve "Parallel Speed" with "Linear Coherence", we split generation into two distinct roles.
- **Rule:** Never let a "Step Bot" (Hands) make global decisions. Never let the "Skeleton Bot" (Brain) write specific content.

## 7.2 The Brain (`generateUnitSkeleton`)
- **Role:** Holistic Commander.
- **Responsibilities:**
    1. **Holistic Analysis:** Reads the *entire* source text to understand the big picture.
    2. **Strict Segmentation ("Divorce"):** Splits the narrative into distinct, NON-OVERLAPPING chunks. Use "Logical Chunking" to prevent merging distinct eras.
    3. **Topic Policing:** Assigns strict `narrative_focus` (Allowed) and `forbidden_topics` (Banned) to each step.
- **Output:** A roadmap with logical boundaries.

## 7.3 The Hands (`generateStepContent`)
- **Role:** Focused Executor.
- **Responsibilities:**
    1. **Blind Obedience:** Writes content *strictly* within the `narrative_focus` provided by the Brain.
    2. **Anti-Amnesia:** Assumes the user read previous steps (no re-definitions).
    3. **Age Adaptation:** Applies "Concrete Analogies" and Simplification.
- **Output:** A single, polished learning block that fits perfectly into the larger puzzle.

# 9. ğŸ›¡ï¸ STRICT INTEGRITY PROTOCOLS
## 8.1 Anti-Leakage (Topic Isolation)
- **Constraint:** A step MUST NOT reveal information belonging to future steps.
- **Mechanism:** The Brain assigns `forbidden_topics` which the Hands must explicitly avoid.

## 8.2 Anti-Hallucination (Strict Grounding)
- **Rule:** "If it's not in the Source Text, it doesn't exist."
- **Prohibition:** No external examples (e.g., modern concepts like "cyberbullying" in historical texts) unless explicitly present in the source.

## 8.3 Linguistic & Tonal Integrity
- **Negative Tone Constraint:** For Grade 7+, explicitly BAN "Second-Person" narrative ("Imagine yourself"). Force "Objective/Historical" tone.
- **Language Lock:** All output values, especially `model_answer` and "Evaluator Guidelines", MUST be in Hebrew.

## 8.4 Pedagogical Safety Valve (Bloom-Preserving Fallback)
- **Problem:** Strict Grounding sometimes clashes with rigid Interaction Types (e.g., asking for an Order when text has no sequence).
- **Rule:** If the requested Interaction Type is impossible given the text, the AI MUST trigger a **Bloom-Preserving Fallback**.
- **The Matrix:**
    1. **Ordering (Apply/Analyze) Failed?** -> Fallback to **Categorization** or **Cloze** (Keep Level 2).
    2. **Categorization (Apply/Analyze) Failed?** -> Fallback to **Cloze** (Keep Level 2).
    3. **Memory Game (Remember) Failed?** -> Fallback to **Multiple Choice** (Keep Level 1).
- **Prohibition:** NEVER return broken JSON or empty lists. Better to degrade the *Type* than to break the *App*.
# 10. ğŸ§© INTERACTION MATRIX & BLOOM MAPPING (Revised)
## 9.1 Remember (Knowledge & Recall)
- **Primary Tool:** `memory_game` (Visual/Text Pairs).
- **Secondary Tool:** `multiple_choice` (Standard).
- **Goal:** Recall facts, definitions, and dates.

## 9.2 Understand (Comprehension)
- **Primary Tool:** `fill_in_blanks` (Contextual Cloze).
- **Secondary Tool:** `true_false` (Interpretation).
    - *Constraint:* Must require interpreting the text, not just Fact Check. "Does the author imply X?" rather than "Is X true?".

## 9.3 Apply & Analyze (Process & Logic)
- **Tool A:** `categorization` (Distinguishing attributes).
- **Tool B:** `ordering` (Logical Sequence / Syllogism).
    - *Constraint:* Focus on PROCESS logic, not rote memorization of dates.

## 9.4 Evaluate & Create (Synthesis)
- **Sole Tool:** `open_question` (Argumentation & Synthesis).
- **Logic:** The only space for original thought and justifiction.

# 11. ğŸ”§ TECHNICAL ARCHITECTURE & STANDARDS (Phase 4)
## 10.1 The "No Any" Policy (Strict Typing)
- **Problem:** `any` types hide bugs and break the "Mirror Reality" principle.
- **Rule:** ALL functional code must use strict TypeScript interfaces defined in `src/types/`.
    - **Forbidden:** Explicit `any`, `unknown` (unless strictly checked).
    - **Authorized Types:** `RawAiItem` (Input), `MappedLearningBlock` (Output), `UnitSkeleton` (Internal).
    - **Status:** *Partial Compliance*. Some legacy blocks in `courseTypes.ts` still use `any`. improving this is a Priority.

## 10.2 The "Mirror Reality" Data Principle
- **Logic:** The code must reflect the data *as it is*, not as we wish it to be.
- **Rule:** Do not force strict schemas on the AI's *output* directly. Map the "Raw" chaotic AI JSON into a "Strict" internal model using a dedicated parser (`mapSystemItemToBlock`).
- **Mechanism:** `RawAiItem` (Union of all possible AI mistakes) -> `MappedLearningBlock` (Strict internal state).

## 10.3 Testing Strategy (Safety Net)
- **Requirement:** No refactoring without a Safety Net.
- **Golden Master Tests:** 
    - Before touching `gemini.ts` or critical logic, run `src/gemini.test.ts`.
    - These snapshot tests guard against regression in the Mapping Logic.
- **Verification:** Unit tests must pass (`npx vitest`) before any commit.

## 10.4 The "Shared Types" Architecture (UI Integration)
- **Logic:** Types should not be trapped in the backend.
- **Rule:** Core Data Structures (`ActivityBlock`, `Assignment`) must live in `src/courseTypes.ts`.
- **Mechanism:** `ActivityBlock` is a **Discriminated Union** (e.g., `{ type: 'multiple-choice', content: MultipleChoiceContent }`). Consumers (UI) MUST use **Type Guards** (e.g., `switch(block.type)`) to access specific content safely.
- **Strict State:** The main `App.tsx` state (`currentAssignment`) must be typed as `Assignment | null`, forbidding `any`.

## 10.5 Development Environment & Auth
- **Problem:** Google/Firebase Auth is difficult to automate or use offline/locally.
- **Solution:** "Mock Login" Bypass.
- **Mechanism:** 
    - `AuthContext` exposes a `mockLogin()` function.
    - A "Dev Login" button appears on the Login screen ONLY when `import.meta.env.DEV` is true.
    - It sets a strict `MOCK_USER` (satisfying Firebase `User` interface) into the global state.
- **Constraint:** This bypass MUST be stripped/disabled in Production builds (guaranteed by `import.meta.env.DEV`).

# 12. ğŸ—ï¸ ACTIVITY STRUCTURE & PACING (The "Wizdi Pyramid")
Educational activities follow a "Scaffolding" structure to ensure learner confidence and depth:

## 11.1 The Distribution Rules
1. **Foundation (Start):** 30-40% of questions focus on Levels 1 (Remember/Understand).
2. **Process (Middle):** 40% of questions focus on Level 2 (Apply/Analyze).
3. **Synthesis (End):** 20% of questions focus on Level 3 (Evaluate/Create).

## 11.2 The Logic (Hard Constraints)
- **Constraint 1:** Never place a Level 3 question as the first step.
- **Constraint 2:** Specific Distribution by Length:
    - **Short (3 Steps):** 1 Remember -> 1 Analyze -> 1 Create.
    - **Long (7 Steps):** 2 Remember -> 3 Apply/Analyze -> 2 Evaluate/Create.

# 13. ğŸ•¹ï¸ OPERATIONAL MODES (V5 Architecture)
## 13.1 Philosophy
The system behaves differently based on the user's explicit intent. We distinguish between **LEARNING** (Pedagogy) and **ASSESSMENT** (Verification).

## 13.2 LEARNING MODE (`mode: 'learning'`)
- **Goal:** Scaffolding, Mentoring, Engagement.
- **Structure:** `Text Chunk -> Question -> Text Chunk -> Question`.
- **Content:**
    - **Teach Content:** Present. Explains concepts before asking.
    - **Tone:** Encouraging, "Wizdi-Bot" Mentor.
    - **Hints:** **MANDATORY**. 2-3 progressive hints per question.
    - **Feedback:** Educational ("Great job! You understood X...").

## 13.3 ASSESSMENT MODE (`mode: 'assessment'`)
- **Goal:** Discrimination, Testing, Verification.
- **Structure:** `Question -> Question -> Question` (Sequence of Items).
- **Strict Protocol:**
    - **Teach Content:** **BANNED**. No teaching blocks allowed.
    - **Tone:** Neutral, Objective, "Strict Examiner".
    - **Hints:** **FORBIDDEN**. Empty array `[]`.
    - **Feedback:** Discriminative ("Correct. X matches Y because...").
- **Blacklisted Activity Types (Strictly Prohibited):**
    - **Interactive Chat:** Risk of answer leakage.
    - **Memory Game:** Gaming mechanic, prone to guessing.
    - **Podcast:** Passive consumption.
    - **Gem Link:** External exit risk.
- **Bloom Taxonomy:** Focuses on higher order (Analyze, Evaluate).

## 13.4 Trigger Logic
- **Cloud Function:** `generateLessonPlan` accepts `data.mode` ('learning' | 'assessment').
- **Brain (Stage 1):** Switches strategy from "Divorce to Teach" to "Scan to Test".
- **Hands (Stage 2):** Switches system prompt to enforce "No Hints" and "No Teach Content".

# 13.5 ğŸ¯ SCORING & GRADING SYSTEM (The "Honest Mirror")
## 13.5.1 Philosophy
The scoring system reflects student performance with **mathematical precision** and **pedagogical honesty**. Points are not arbitrary rewards but meaningful signals of mastery, effort, and independence.

## 13.5.2 Core Scoring Constants
**Location:** `src/utils/scoring.ts`

```typescript
SCORING_CONFIG = {
    CORRECT_FIRST_TRY: 100,    // Perfect mastery
    HINT_PENALTY: 2,            // Cost per hint used (-2 points each)
    RETRY_PARTIAL: 50,          // Partial credit for retry success
}
```

## 13.5.3 Scoring Logic Matrix
| Scenario | Attempts | Hints Used | Score Calculation | Example |
|----------|----------|------------|-------------------|---------|
| **Perfect Mastery** | 1 | 0 | `100` | First try, no help â†’ 100 points |
| **Scaffolded Success** | 1 | 2 | `100 - (hints Ã— 2)` | First try with 2 hints â†’ 96 points |
| **Persistent Learning** | 2+ | 0 | `50` | Retry after failure â†’ 50 points |
| **Scaffolded Retry** | 2+ | 1 | `50` (no additional penalty) | Retry already penalized â†’ 50 points |
| **Incorrect** | Any | Any | `0` | Failed answer â†’ 0 points |

## 13.5.4 Implementation Architecture
### The Central Function
**Location:** `src/utils/scoring.ts:calculateQuestionScore()`

This function is the **SINGLE SOURCE OF TRUTH** for all scoring. All question types must use it.

**âœ… MANDATORY Usage Pattern:**
```typescript
const score = calculateQuestionScore({
    isCorrect: boolean,
    attempts: number,      // 1 for first try, 2+ for retries
    hintsUsed: number,     // Count of hints revealed
    responseTimeSec: number // For telemetry (not used in scoring yet)
});
```

### Integration Points
1. **SequentialCoursePlayer** (Main flow): Uses scoring to calculate XP and Gems
2. **ClozeQuestion**: Applies partial credit for partially correct answers
3. **OrderingQuestion**: Binary correct/incorrect with attempt tracking
4. **MemoryGameQuestion**: Caps attempts at 3 to avoid excessive penalty

## 13.5.5 Gamification Integration
**XP Rewards:** Directly tied to score (0-100 points = 0-100 XP)

**Gem Rewards:**
- Perfect score (100): 2 gems
- Partial/Retry (50-99): 1 gem
- Incorrect (0): 0 gems

**Combo System:** REMOVED in favor of honest scoring. Previous combo bonuses created artificial inflation.

## 13.5.6 Exam Mode Scoring
- **Hints:** Forbidden (empty array enforced)
- **Feedback:** Delayed until submission
- **Score Recording:** Same logic but no XP/Gems (assessment focus)

## 13.5.7 Critical Rules (MUST FOLLOW)
1. **Never bypass `calculateQuestionScore()`** - All scoring MUST go through the central function
2. **Track hints accurately** - Use `hintsVisible` state to count revealed hints
3. **Count attempts correctly** - First submission = attempt 1, retry = attempt 2+
4. **No artificial bonuses** - Score reflects mastery, not gameplay mechanics

## 13.5.8 Quality Assurance
- **Unit Tests:** `src/utils/scoring.test.ts` validates all scenarios
- **Console Logging:** Scoring decisions logged in development mode
- **Teacher Visibility:** Scores visible in TeacherCockpit with attempt/hint breakdown

## 13.5.9 Progressive Hints System (Scaffolding Implementation)
### Philosophy
Hints are pedagogical scaffolding tools that guide students to answers without giving them away. They are **mandatory in Learning Mode** and **forbidden in Exam Mode**.

### Implementation
All interactive question components now support progressive hints:

**Supported Components:**
- âœ… `OrderingQuestion` - Hints about sequence logic
- âœ… `ClozeQuestion` - Hints about context clues
- âœ… `CategorizationQuestion` - Hints about category criteria
- âœ… `MultipleChoiceQuestion` (already supported)
- âœ… `OpenQuestion` (already supported)

**Interface Pattern:**
```typescript
interface QuestionProps {
    block: ActivityBlock;
    onComplete?: (score: number, telemetry?: TelemetryData) => void;
    isExamMode?: boolean;        // If true, hints UI is hidden
    hints?: string[];             // Array of progressive hints
    onHintUsed?: () => void;      // Callback when hint revealed
}
```

### UX Behavior
1. **Hint Lock:** Hints are disabled until the student makes first attempt (prevents hint dependency)
2. **Progressive Reveal:** Hints appear one at a time, not all at once
3. **Visual Design:** Yellow theme (`bg-yellow-50`, `border-yellow-300`) for hint cards
4. **Counter Display:** Shows "×¨××– × ×•×¡×£ (2/3)" to indicate progress
5. **Exam Mode:** Entire hints section hidden when `isExamMode={true}`

### Scoring Integration
- Each hint revealed increments `hintsUsedRef`
- Final score calculation: `100 - (hintsUsed Ã— HINT_PENALTY)`
- Telemetry includes `hintsUsed` count for teacher analytics

### AI Generation Requirements
When generating content, AI must provide 2-3 progressive hints per question:
- **Level 1 (Location):** "×©×™××• ×œ×‘ ×œ××©×¤×˜ ×©××ª×—×™×œ ×‘..." (Point to text location)
- **Level 2 (Simplification):** "×”××™×œ×” ×”× ×›×•× ×” ×§×©×•×¨×” ×œ..." (Rephrase concept)
- **Level 3 (Strong Nudge):** "×”×¤×¨×™×˜ ×”×¨××©×•×Ÿ ××ª×—×™×œ ×‘××™×œ×”..." (Almost give answer)

**Prompt Integration:** Ensure `progressive_hints` array populated in AI output for all question types.

# 14. ğŸ•µï¸ STUDENT PROFILING ENGINE ("The Silent Observer")
## 14.1 Philosophy
The system tracks more than just "Correct/Incorrect". It builds a granular behavioral profile to understand *how* the student learns.

## 14.2 Data Schema (Firestore)
- **Path:** `users/{userId}/profile/stats`
- **Performance:**
    - `average_response_time_sec`: Rolling average of thinking time.
    - `global_accuracy_rate`: 0.0 to 1.0.
    - `error_rate_by_topic`: Map of mistakes per topic.
- **Behavioral:**
    - `hint_dependency_score`: (0.0 - 1.0) Do they ask for help immediately?
    - `retry_persistence`: Do they try again after failure?
    - `media_preference`: Score for text vs video vs gamified content.

## 14.3 Telemetry & Aggregation
- **Frontend Hook:** `useStudentTelemetry` tracks precise events (Question Start, Hint Request, Answer Submit).
- **Backend Service:** `profileService.ts` aggregates raw session data into the persistent profile using atomic transactions.

# 15. ğŸ¤– AUTOMATED PROMPT ENGINEERING ("Smart Grouping")
## 15.1 Philosophy
Transforming "Classroom Groups" into "AI Instructions". The teacher clicks a group, the AI receives a tailored persona.

## 15.2 The Logic (LessonDistributor)
| Group Type | Bloom Level | Tone | Scaffolding | Preferred Modules |
| :--- | :--- | :--- | :--- | :--- |
| **Remediation** | Remember / Understand | Encouraging / Mentor | High (More Hints) | Memory Game, Sorting, Simple Quiz |
| **Standard** | Apply / Analyze | Balanced | Standard | Multiple Choice, Matching |
| **Challenge** | Evaluate / Create | Intellectual / Socratic | Low (Less Hints) | Open Questions, Logic Ordering, Escape Room |

## 15.3 Workflow
1. **Selection:** Teacher selects a group in `SmartGroupingPanel`.
2. **Translation:** `generateGroupConfig` converts the group type into specific system prompts ("Break down complex terms", "Ask open questions").
3. **Queueing:** A job is pushed to `lesson_generation_queue` with the `studentIds` list for auto-assignment.

# 16. ğŸ—£ï¸ FEEDBACK LOOP & INSIGHT ENGINE
## 16.1 Philosophy
The system does not just "push" content; it "listens" to the user. We combine **Implicit Signals** (Telemetry) with **Explicit Feedback** (Ratings) to create a self-improving loop.

## 16.2 Architecture components
- **The Ear (Data Collection):** Low-friction input mechanisms embedded in the learning flow.
    - *Student:* "Micro-Feedback" (Thumbs Up/Down) on every granular interaction.
    - *Teacher:* "Wizdi Monitor" for reporting content quality or relevance issues.
- **The Brain (Insight Engine):** Asynchronous AI service that aggregates logs and generates actionable insights (`SystemInsight`).
- **The Hand (Action):** Direct connection to `LessonDistributor` to adjust future content based on feedback.

## 16.3 Data Schema (`feedback_logs`)
- **Core Entity:** `FeedbackLog`
    - `type`: 'positive' | 'negative'
    - `tags`: ['confusing', 'boring', 'too_easy', 'technical_issue', 'innaccurate']
    - `context`: `{ blockId, unitId, courseId, gradeLevel }`
    - `userRole`: 'student' | 'teacher'

## 16.4 Operational Rules
1.  **Exam Mode Silence:** Feedback widgets are **HIDDEN** during exams to prevent distraction and maintain integrity.
2.  **Frictionless First:** The primary interaction is a single click (Thumb). Tag selection is secondary/optional.
3.  **Real-Time Persistence:** Feedback is written immediately to Firestore to ensure no data loss during session drops.

# 17. ğŸ§­ ADAPTIVE DIFFERENTIAL LEARNING (ADLS)
## 17.1 Philosophy (The "Wizdi Adaptive Engine")
We are transitioning from a linear "content consumption" model to a dynamic "Knowledge Graph" traversal. The system acts as a real-time tutor that observes, analyzes, and adapts to every student interaction.

## 17.2 Theoretical Frameworks
1.  **Item Response Theory (IRT):**
    *   **Difficulty ($\beta$):** Probability of correct answer.
    *   **Discrimination ($\alpha$):** Ability to differentiate high vs low performers.
    *   **Guessing ($c$):** Probability of random success.
2.  **Zone of Proximal Development (ZPD):**
    *   Target Success Rate: **60-70%**.
    *   **>90%:** Increase Difficulty (Challenge).
    *   **<40%:** Decrease Difficulty (Scaffold/Remediate).

## 17.3 The "Backend Brain" (BKT Engine) - IMPLEMENTED
- **Model:** Bayesian Knowledge Tracing (BKT).
- **Parameters:** $P(L_0)=0.1$ (Init), $P(T)=0.1$ (Learn), $P(S)=0.1$ (Slip), $P(G)=0.25$ (Guess).
- **Architecture:** Firebase Cloud Function `submitAdaptiveAnswer`.
- **Policy:**
    - `Mastery > 0.9` -> **Challenge** (Skip next easy topic).
    - `Mastery < 0.4` -> **Remediate** (Trigger Factory).
    - `Else` -> **Continue** (Standard Flow).

## 17.4 The "Content Factory" (Real-time Remediation) - IMPLEMENTED
- **Trigger:** Failed BKT check (`Action: REMEDIATE`).
- **Mechanism:** `adaptiveContentService` calls LLM with:
    - Failed Question Context.
    - Specific Wrong Answer (Misconception Analysis).
- **Output:** A "Bridge Block" (Text/Explanation) < 80 words.
- **Injection:** Spliced into `SequentialCoursePlayer` queue immediately (`playbackQueue.splice(current+1, 0, remediation)`).

## 17.5 The "Neural Dashboard" (Teacher Visualization) - IMPLEMENTED
- **Route:** `/analytics`.
- **Views:**
    1.  **Heatmap (The Matrix):** Grid of Student x Topic mastery.
    2.  **Journey Trace (DNA Strand):** Visual subway map of learning path.
        - ğŸŸ¢ Green Node: Success.
        - ğŸ”´ Red Node: Failure.
        - ğŸŸ¡ Yellow Node: Adaptive Remediation Loop (The "Self-Correction").
- **Insight:** AI-generated class-level summaries.
3.  **Bayesian Knowledge Tracing (BKT):**
    *   Student Model is a probabilistic state vector, updated after *every* interaction.

## 17.3 Smart Question Schema
Atomic units must contain metadata for the Policy Engine:
-   **IRT Meta:** `difficulty_level` (0.0-1.0), `bloom_taxonomy`.
-   **Adaptive Logic:**
    -   `distractors`: Each wrong answer has an `error_tag` (e.g., "calculation_error", "misconception").
    -   `next_action`: Specific trigger per answer (e.g., "retry_with_hint", "remediate_concept").
-   **Relations:** `scaffolding_id` (simpler variant) and `enrichment_id` (harder variant).

## 17.4 The Policy Engine (Algorithm)
Executed between steps (Wizard Mode):
1.  **Evaluate:** Correctness + Time + Error Tag.
2.  **Update State:** Modify Student Proficiency Vector (BKT).
3.  **Decide Strategy:**
    -   *Fast + Correct* â†’ **Challenge** (+Difficulty).
    -   *Slow + Correct* â†’ **Reinforce** (Same Difficulty).
    -   *Incorrect + Slip* â†’ **Retry** (Hint).
    -   *Incorrect + Concept* â†’ **Remediate** (Explanation/Scaffold).

## 17.5 UI/UX Transition: Wizard Mode
-   **Requirement:** "Sequential View" is mandatory for adaptivity.
-   **Mechanic:** Submission triggers `POST /nextStep`, rendering the next block dynamically.
-   **Visuals:** "Mastery Bar" replaces "Question Count".

## 17.6 Gamified Feedback Loop
-   **Three-State Button:** Primary action morphs: Check (Lime) -> Success (Green) / Failure (Red).
-   **Immediate Gratification:** XP "Floaters" and Streak "Flames" provide visceral confirmation of competence.
-   **Adaptive Toasts:** System explicitly informs user of adaptive leaps ("Challenge Unlocked").

# 18. ğŸ­ OPERATIONAL AGENTS (The Work Force)
## 18.1 Agent 1: "The Living Loop" (Remediation UX)
- **Goal:** Transform the "Moment of Failure" into a pedagogical opportunity.
- **Methodology:**
    - **Visual:** Use `ThinkingOverlay` (Brain Pulse) instead of static text during generic latency.
    - **Transition:** Seamless fade-in of the Remedial Block.
    - **Integrity:** NEVER modify the BKT logic (`submitAdaptiveAnswer`). ONLY enhance the presentation layer.

## 18.2 Agent 2: "The Economy" (Gamification Persistence)
- **Goal:** Create an "Engagement Lock-in" via persistent value.
- **Methodology:**
    - **Data:** Sync local state (`sessionXp`, `streak`) to Firestore (`users/{uid}/gamification`).
    - **Economy:** Implement `ShopModal` for spending Gems on "Streak Freezes".
    - **Integrity:** Graceful fallback if DB is unreachable. The Lesson must continue even if XP fails to save.

## 18.3 Agent 3: "Neural Insights" (Actionable Dashboard)
- **Goal:** Turn data into immediate pedagogical action.
- **Methodology:**
    - **Smart Logic:** The "Create Unit" button behaves differently based on student state:
        - **Struggling (<60%):** Generates **Remediation** (Scaffolding, simpler terms).
        - **Excelling (>90%):** Generates **Challenge/Enrichment** (Deep dive, higher Bloom).
    - **Class View:** "Wizdi Insights" widget aggregates trends (e.g., "30% struggled with Topic X").

## 18.4 Agent 4: "Adaptive Content Factory" (Ingestion Pipeline)
- **Goal:** Zero-friction creation of diverse product types.
- **Methodology:**
    - **Differentiation:** `generateUnitSkeleton` accepts `productType`:
        - `game`: Forces `memory_game`, `ordering`, `categorization`. Minimizes text.
        - `exam`: Forces `mode: assessment`. No teaching blocks.
        - `lesson`: Standard narrative flow.

# 19. ğŸ¤– AI AGENTS REGISTRY (Complete System Map)
*Last Updated: 2026-01-04*

## 19.1 Overview
This section documents ALL AI agents in the system, their locations, purposes, and configurations. The system uses a multi-agent architecture with specialized agents for different tasks.

## 19.2 Core AI Services

### 19.2.1 Teacher Persona Bots (4 Personalities)
- **File:** `src/services/ai/prompts.ts`
- **Agent Names:**
  | Persona | Hebrew Name | Behavior | Use Case |
  |---------|-------------|----------|----------|
  | **Teacher** | ×”××•×¨×” ×”××œ×•×•×” | Gently corrects, encouraging | Default tutoring |
  | **Socratic** | ×”×× ×—×” ×”×¡×•×§×¨×˜×™ | Questions with questions | Critical thinking |
  | **Concise** | ×”×ª××¦×™×ª×™ | 2-3 sentence answers | Quick help |
  | **Coach** | ×”××××Ÿ ×”×××ª×’×¨ | Pushes students further | Advanced learners |
- **Integration:** `AiTutor.tsx` component, uses OpenAI GPT-4o-mini via proxy

### 19.2.2 AI Tutor Chat Component
- **File:** `src/components/AiTutor.tsx`
- **Purpose:** Interactive AI tutoring chatbot
- **Features:**
  - Safety checks (distress detection)
  - Input validation & security filtering
  - Selectable personas from 19.2.1
- **Model:** GPT-4o-mini via `openaiProxy`

## 19.3 Exam Generation Pipeline (3-Stage Architecture)

### 19.3.1 Stage 1: Exam Architect
- **File:** `functions/src/services/examArchitect.ts`
- **Prompts:** `functions/src/ai/examPrompts.ts`
- **Role:** Strategic test planner
- **Responsibilities:**
  - Analyzes source material holistically
  - Creates test structure and question specifications
  - Assigns Bloom taxonomy levels
  - Ensures balanced topic coverage
- **Temperature:** 0.3 (deterministic)
- **Output:** `ExamSkeleton` with estimated time, difficulty levels, point allocation

### 19.3.2 Stage 2: Exam Generator
- **File:** `functions/src/services/examGenerator.ts`
- **Role:** Question creator
- **Responsibilities:**
  - Generates individual exam questions
  - Creates rigorous, assessment-focused content
  - No hints or teaching (exam-only mode)
  - Supports: MCQ, True/False, Fill-in, Ordering, Open questions
- **Temperature:** 0.3 (deterministic)
- **Output:** Generated questions with distractor analysis and rubrics

### 19.3.3 Stage 3: Exam Guardian
- **File:** `functions/src/services/examGuardian.ts`
- **Role:** Integrity validator (QA)
- **Responsibilities:**
  - Checks for hint/teaching content leaks
  - Validates formal, objective tone
  - Detects answer reveals in feedback
  - Checks for bias (cultural, gender, socioeconomic)
  - Evaluates accessibility
- **Temperature:** 0.1 (very strict)
- **Output:** Quality score (0-100) + validation report

## 19.4 Content Generation Agents

### 19.4.1 Unit Skeleton Generator (Brain)
- **File:** `functions/src/controllers/aiController.ts`
- **Functions:**
  - `generateTeacherLessonPlan()` - 5E Model lesson plans
  - `generateStudentUnitSkeleton()` - Interactive learning units
- **Role:** Holistic commander - plans structure without writing content
- **Output:** Roadmap with logical boundaries

### 19.4.2 Step Content Generator (Hands)
- **File:** `functions/src/controllers/aiController.ts`
- **Function:** `generateStepContent()`
- **Role:** Focused executor - writes within boundaries set by Brain
- **Features:** Multi-modal content (text + images)

### 19.4.3 Question Generator Suite
- **File:** `src/services/ai/geminiApi.ts`
- **Functions:**
  | Function | Output Type |
  |----------|-------------|
  | `generateSingleMultipleChoiceQuestion()` | MCQ |
  | `generateSingleOpenQuestion()` | Open-ended |
  | `generateCategorizationQuestion()` | Sorting/categorization |
  | `generateOrderingQuestion()` | Sequencing |
  | `generateFillInBlanksQuestion()` | Cloze text |
  | `generateMemoryGame()` | Matching pairs |

### 19.4.4 Content Validation Agent
- **File:** `src/services/ai/geminiApi.ts`
- **Function:** `validateContent()`
- **Purpose:** Pedagogical validation
- **Checks:** Readability, cognitive load, CEFR level, structural integrity

### 19.4.5 Content Refinement Agent
- **File:** `src/services/ai/geminiApi.ts`
- **Function:** `refineContentWithPedagogy()`
- **Purpose:** Improves content based on pedagogical instructions

### 19.4.6 AI Auto-Fix Agent
- **File:** `functions/src/controllers/aiController.ts`
- **Function:** `attemptAutoFix()`
- **Purpose:** Automatically fixes validation issues
- **Temperature:** 0.3

## 19.5 Assessment & Grading Agents

### 19.5.1 Automated Grading Service
- **File:** `src/services/gradingService.ts`
- **Function:** `gradeBatch()`
- **Purpose:** Auto-grades open-ended questions using AI
- **Features:** Batch processing, rubric-based, student feedback

### 19.5.2 Student Answer Evaluator
- **File:** `src/services/ai/geminiApi.ts`
- **Function:** `checkOpenQuestionAnswer()`
- **Modes:**
  - Learning: Guiding feedback
  - Exam: Strict evaluation
- **Output:** Status (correct/partial/incorrect) + feedback

### 19.5.3 Grading Agent
- **File:** `src/services/ai/geminiApi.ts`
- **Function:** `generateGrading()`
- **Output:** JSON with grades (0-100) + constructive feedback in Hebrew

## 19.6 Analytics Agents

### 19.6.1 Student Analysis Agent
- **File:** `src/services/ai/geminiApi.ts`
- **Function:** `generateStudentAnalysis()`
- **Output:** Strengths, weaknesses, recommended focus, engagement score, learning metrics

### 19.6.2 Class Analysis Agent
- **File:** `src/services/ai/geminiApi.ts`
- **Function:** `generateClassAnalysis()`
- **Output:** Class strengths, weak skills, teaching strategies, students needing attention

### 19.6.3 Student Report Generator
- **File:** `src/services/ai/geminiApi.ts`
- **Function:** `generateStudentReport()`
- **Output:** JSON report with summary, knowledge assessment, recommendations

## 19.7 Adaptive Content Service
- **File:** `src/services/adaptiveContentService.ts`
- **Function:** `enrichActivityBlock()`
- **Purpose:** Enriches learning blocks with pedagogical metadata
- **Features:**
  - Difficulty level estimation (IRT Beta)
  - Bloom taxonomy classification
  - Error tagging for distractors
  - Misconception analysis

## 19.8 Media Generation Agents

### 19.8.1 Podcast Script Generator
- **File:** `src/services/audioGenerator.ts`
- **Function:** `generateScript()`
- **Format:** Two-host dialogue (Dan - analytical, Noa - curious)
- **Language:** Hebrew (configurable)
- **Temperature:** 0.7 (creative)

### 19.8.2 Detailed Script Generator
- **File:** `src/services/ai/geminiApi.ts`
- **Function:** `generatePodcastScript()`
- **Output:** `DialogueScript` with speaker roles and emotional cues

### 19.8.3 Image Generation (DALL-E 3)
- **File:** `src/services/ai/geminiApi.ts`
- **Function:** `generateAiImage()`
- **Cost:** $0.040 per image
- **Features:** Fallback mechanism, cost-effective provider selection

### 19.8.4 Image Generation (Imagen 3)
- **File:** `src/services/ai/imagenService.ts`
- **Function:** `generateImagenImage()`
- **Cost:** $0.020 per image (50% cheaper)
- **Status:** Optional, requires Cloud Function deployment

### 19.8.5 Infographic Generator
- **File:** `src/services/ai/geminiApi.ts`
- **Function:** `generateInfographicFromText()`
- **Types:** Flowchart, Timeline, Comparison, Cycle
- **Features:**
  - Dual-tier caching (memory + Firebase Storage)
  - Analytics tracking
  - Hebrew-optimized prompts

### 19.8.6 Text-to-Speech (ElevenLabs)
- **File:** `src/services/elevenLabs.ts`
- **Features:**
  - Multi-language voice support
  - Automatic language detection (Hebrew/English)
  - Gendered voice options

## 19.9 Infrastructure & Proxy Agents

### 19.9.1 OpenAI Proxy Function
- **File:** `functions/src/index.ts`
- **Function:** `openaiProxy`
- **Purpose:** Proxies OpenAI requests with:
  - Firebase Auth validation
  - Rate limiting by request type
  - Cost control and monitoring

### 19.9.2 YouTube Transcription
- **File:** `functions/src/index.ts`
- **Function:** `transcribeYoutube()`
- **Features:** Multi-language support, fallback strategy

### 19.9.3 Imagen Proxy
- **File:** `functions/src/imagenProxy.ts`
- **Functions:** `generateImagenImage()`, `imagenHealthCheck()`, `imagenStats()`
- **Purpose:** Proxies Vertex AI with monitoring

## 19.10 QA & Testing Agents

### 19.10.1 IDO QA Agent
- **File:** `scripts/ido_qa_agent.ts`
- **Purpose:** QA testing bot simulating 14-year-old tester
- **Features:**
  - Static analysis (Readiness Check)
  - Dynamic user interaction simulation
  - Bug report generation
- **Output:** JSON test reports with pass/fail status

## 19.11 Model & Cost Configuration
| Use Case | Model | Temperature | Cost |
|----------|-------|-------------|------|
| Primary Generation | GPT-4o-mini | 0.3-0.5 | Low |
| Quality Validation | GPT-4o | 0.1 | Medium |
| Creative Content | GPT-4o-mini | 0.7 | Low |
| Strict Validation | GPT-4o | 0.1 | Medium |
| Image (Standard) | DALL-E 3 | - | $0.040 |
| Image (Economy) | Imagen 3 | - | $0.020 |

## 19.12 Prompt Files Registry
| File | Purpose |
|------|---------|
| `src/services/ai/prompts.ts` | Bot personas, validation prompts |
| `src/prompts/pedagogicalPrompts.ts` | Linguistic validation, structural integrity |
| `src/prompts/audioPrompts.ts` | Podcast script generation |
| `functions/src/ai/prompts.ts` | Backend skeleton & step prompts |
| `functions/src/ai/examPrompts.ts` | Exam 3-stage pipeline prompts |

# 20. ğŸ›¡ï¸ AGENTIC SAFETY PROTOCOL (The Shield)
## 19.1 Regression Prevention
- **Rule:** "Do No Harm."
- **Mandate:** Before upgrading a UI component (e.g., Player), ensure the *existing* flow works. New features (Overlays) must be additive, not destructive.

## 19.2 Pedagogical Timing & Latency
- **Rule:** Animation for animation's sake is forbidden.
- **Limit:** `ThinkingOverlay` should reflect *actual* processing time. If the backend is fast (<500ms), do NOT force an artificial "fake thinking" delay > 1.5s.

## 19.3 Logic Preservation
- **Rule:** The BKT Engine (`submitAdaptiveAnswer`) is the Core Truth. Agents may read from it, but only the `Adaptive Brain` (Cloud Function) may write to it.

# 21. ğŸ“š KNOWLEDGE BASE & RAG SYSTEM (The Curriculum Brain)
*Last Updated: 2026-01-08*

## 21.1 Philosophy
The Knowledge Base is a **Retrieval Augmented Generation (RAG)** system that grounds AI-generated content in **actual curriculum materials**. Instead of relying solely on the LLM's training data, the system retrieves relevant educational content from uploaded textbooks and teacher guides.

## 21.2 Architecture Overview
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    KNOWLEDGE BASE PIPELINE                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  ğŸ“„ PDF Upload                                                   â”‚
â”‚       â”‚                                                          â”‚
â”‚       â–¼                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ PDF         â”‚â”€â”€â”€â”€â–¶â”‚ Text         â”‚â”€â”€â”€â”€â–¶â”‚ Embedding       â”‚  â”‚
â”‚  â”‚ Processor   â”‚     â”‚ Chunking     â”‚     â”‚ Generation      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ (OpenAI)        â”‚  â”‚
â”‚                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                    â”‚            â”‚
â”‚                                                    â–¼            â”‚
â”‚                                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                                           â”‚ Firestore       â”‚  â”‚
â”‚                                           â”‚ (math_knowledge)â”‚  â”‚
â”‚                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                    â”‚            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚  â”‚                                                              â”‚
â”‚  â–¼                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              CONTENT GENERATION FLOW                      â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  Topic + Grade  â”€â”€â–¶ Semantic Search â”€â”€â–¶ Relevant Chunks  â”‚  â”‚
â”‚  â”‚                          â”‚                     â”‚          â”‚  â”‚
â”‚  â”‚                          â–¼                     â–¼          â”‚  â”‚
â”‚  â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚                   â”‚ AI Prompt with KB Context:       â”‚   â”‚  â”‚
â”‚  â”‚                   â”‚ â€¢ Curriculum Reference Material  â”‚   â”‚  â”‚
â”‚  â”‚                   â”‚ â€¢ Student Textbook Content       â”‚   â”‚  â”‚
â”‚  â”‚                   â”‚ â€¢ Teacher Guide Insights         â”‚   â”‚  â”‚
â”‚  â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â”‚                               â”‚                          â”‚  â”‚
â”‚  â”‚                               â–¼                          â”‚  â”‚
â”‚  â”‚                   ğŸ“ Grade-Appropriate Content           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 21.3 Core Components

### 21.3.1 Knowledge Service
- **File:** `functions/src/services/knowledgeBase/knowledgeService.ts`
- **Key Functions:**
  | Function | Purpose |
  |----------|---------|
  | `uploadDocument()` | Process PDF into vectorized chunks |
  | `search()` | Semantic similarity search |
  | `searchForPromptContext()` | Build AI prompt context from KB |
  | `getStats()` | Knowledge base statistics |
  | `deleteDocument()` | Remove document and chunks |

### 21.3.2 Embedding Service
- **File:** `functions/src/services/knowledgeBase/embeddingService.ts`
- **Model:** OpenAI `text-embedding-3-small` (1536 dimensions)
- **Features:** Batch processing, similarity calculation

### 21.3.3 PDF Processor
- **File:** `functions/src/services/knowledgeBase/pdfProcessor.ts`
- **Features:**
  - Chapter detection (Hebrew patterns: ×¤×¨×§, ×™×—×™×“×”, × ×•×©×, ×©×™×¢×•×¨)
  - Content type classification (explanation, example, exercise, solution, etc.)
  - Smart chunking with overlap

## 21.4 Data Schema

### 21.4.1 Knowledge Chunk (`math_knowledge` collection)
```typescript
interface KnowledgeChunk {
  id: string;

  // Curriculum Location
  subject: 'math' | 'hebrew' | 'english' | 'science' | 'history' | 'other';
  grade: '×' | '×‘' | '×’' | '×“' | '×”' | '×•' | '×–' | '×—' | '×˜' | '×™' | '×™×' | '×™×‘';
  volume: number;           // ×›×¨×š (1, 2, 3...)
  volumeType: 'student' | 'teacher';  // ×¡×¤×¨ ×ª×œ××™×“ ××• ××“×¨×™×š ×œ××•×¨×”

  // Book Location
  chapter: string;
  chapterNumber?: number;
  pageRange?: string;       // "×¢×' 45-52"

  // Content
  content: string;
  contentType: 'explanation' | 'example' | 'exercise' | 'solution' |
               'tip' | 'common_mistake' | 'definition' | 'rule' | 'summary';

  // Vector Embedding
  embedding: number[];      // 1536 dimensions

  // Metadata
  source: string;           // Original file name
  keywords: string[];
  relatedTopics: string[];

  // Usage Tracking
  usageCount: number;
  lastUsedAt?: Timestamp;
}
```

## 21.5 Integration with Content Generation

### 21.5.1 Backend Integration
- **File:** `functions/src/controllers/aiController.ts`
- **Integration Points:**

  | Function | KB Usage | Chunks Retrieved |
  |----------|----------|------------------|
  | `generateStudentUnitSkeleton()` | Auto-fetch by topic+grade | 5 chunks |
  | `generateStepContent()` | Auto-fetch by narrative_focus | 3 chunks |

### 21.5.2 Context Priority Rules
```
Priority 1: User-provided sourceText (explicit override)
Priority 2: Knowledge Base context (curriculum-aligned)
Priority 3: Topic-only (LLM general knowledge - fallback)
```

### 21.5.3 Grade Format Conversion
The system converts various grade formats to KB format:
- "×›×™×ª×” ×‘×³" â†’ "×‘"
- "Grade 2" â†’ "×‘"
- "2" â†’ "×‘"
- "second" â†’ "×‘"

## 21.6 Cloud Functions

| Function | Purpose | Auth |
|----------|---------|------|
| `uploadKnowledge` | Admin: Upload and process PDFs | Admin only |
| `searchKnowledge` | Search knowledge base | Authenticated |
| `getKnowledgeContext` | Get context for AI generation | Authenticated |
| `getKnowledgeStats` | Admin: View KB statistics | Admin only |
| `deleteKnowledgeDocument` | Admin: Delete documents | Admin only |

## 21.7 Chunk Configuration
```typescript
CHUNK_CONFIG = {
  maxTokens: 500,           // ~375 Hebrew words
  overlapTokens: 50,        // Context continuity
  minChunkLength: 100,      // Minimum valid chunk
}
```

## 21.8 Search Parameters
- **Default limit:** 5 results
- **Minimum similarity:** 0.7 (70% semantic match)
- **Max fetch for comparison:** 500 candidates

## 21.9 Usage Tracking
Every retrieval automatically:
1. Increments `usageCount` on retrieved chunks
2. Updates `lastUsedAt` timestamp
3. Enables analytics on most-used content

## 21.10 Critical Rules

### âœ… DO:
1. **Always check KB first** - Before falling back to general LLM knowledge
2. **Respect grade filtering** - Only retrieve content for the target grade
3. **Include teacher guide** - 40% of context should come from teacher guides
4. **Log KB operations** - Track success/failure for debugging
5. **Graceful degradation** - Continue without KB if lookup fails

### âŒ DON'T:
1. **Never skip KB for curriculum content** - It ensures grade-appropriate material
2. **Never ignore volumeType filtering** - Student vs teacher content serves different purposes
3. **Never expose embeddings** - Return chunks without the 1536-dimension vectors
4. **Never hardcode grade strings** - Use `gradeToKBFormat()` helper

## 21.11 Logging & Monitoring
```
ğŸ” Fetching Knowledge Base context for topic: "×—×™×‘×•×¨ ×•×—×™×¡×•×¨", grade: ×‘
ğŸ“š Knowledge Base returned 2847 chars of context
ğŸ“š Step 3: KB returned 1523 chars
âš ï¸ Knowledge Base lookup failed (continuing without): [error message]
```

## 21.12 Future Enhancements
- [ ] Support additional subjects beyond math
- [ ] Implement cross-grade prerequisite detection
- [ ] Add quality scoring for chunks
- [ ] Implement Firestore Vector Search for better performance at scale
- [ ] Add multi-language embedding support
